============================================================
FLUX LORA TRAINING DIAGNOSTIC
============================================================

Python: D:\AI\kohya_ss\venv\Scripts\python.exe
PyTorch: 2.6.0+cu124
CUDA available: True
GPU: NVIDIA GeForce RTX 3060
VRAM: 11.0 GB free / 12.0 GB total

--- STEP 1: Load fp8 checkpoint ---
Loaded 1442 keys
First key dtype: torch.float8_e4m3fn
VRAM after cleanup: 11.0 GB free

--- STEP 2: Forward + backward pass test ---
Simple backward pass OK, loss=-29.7500

--- STEP 3: AdamW8bit optimizer test ---
AdamW8bit step OK

--- STEP 4: Kohya Flux model load ---
Imported flux_utils OK
Loading Flux model (this takes a minute)...
  Loading checkpoint to CPU...
  Loaded 1442 tensors to CPU
  VRAM: 10.9 GB free
  Moving a single tensor to GPU as bf16...
  Moved model.diffusion_model.double_blocks.0.img_attn.norm.key_norm.scale: torch.Size([128]) torch.bfloat16 on cuda:0
  VRAM: 10.9 GB free

--- STEP 5: Test accelerate ---
Imported Accelerator OK
  Creating accelerator with mixed_precision=bf16...
  Accelerator device: cuda
  Num processes: 1
  Distributed type: DistributedType.NO

============================================================
ALL DIAGNOSTIC STEPS PASSED
============================================================

Done. Log saved to: C:\users\adrxi\Earthback\training-diagnostic.log
